{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初步训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import AlexNet\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"1-3\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = AlexNet()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import VGG\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"1-3\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 32\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = VGG()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.0\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import Inception3\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"1-3\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = Inception3()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.0\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import ResNet\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"1-3\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = ResNet()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.0\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据增强测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import ResNet\n",
    "from DataLoader import load_mag_data_augment\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"1-3\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "    \n",
    "    # 对训练集作数据增强\n",
    "    train_iter = load_mag_data_augment(csv=train_csv, root=root, batch_size=batch_size, \n",
    "                                       shuffle=True, num_workers=16, \n",
    "                                       X_aug=True, M_aug=True)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = ResNet()        # batch_size = 96\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据重采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import ResNet\n",
    "from DataLoader import load_mag_data_sampler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"1-3\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "    \n",
    "    # 对训练集作数据重采样\n",
    "    train_iter = load_mag_data_sampler(csv=train_csv, root=root, transform=trans, \n",
    "                                       batch_size=batch_size, num_workers=16, \n",
    "                                       sampler_type='weighted')\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = ResNet()        # batch_size = 96\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加权损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import AlexNet\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "def _criterion_weight(csv):\n",
    "    \"\"\"计算损失函数权重\"\"\"\n",
    "    csv = pd.read_csv(csv); N = len(csv)\n",
    "    counts = csv['label'].value_counts().to_dict()\n",
    "    labels = ['NF', 'C', 'M', 'X']; K = len(labels)\n",
    "    weight = torch.tensor([N / (K * counts.get(label)) for label in labels], dtype=torch.float32)\n",
    "    return weight\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"10-12\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = AlexNet()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    criterion_weight = _criterion_weight(train_csv)\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          criterion_weight = criterion_weight,\n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import VGG\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "def _criterion_weight(csv):\n",
    "    \"\"\"计算损失函数权重\"\"\"\n",
    "    csv = pd.read_csv(csv); N = len(csv)\n",
    "    counts = csv['label'].value_counts().to_dict()\n",
    "    labels = ['NF', 'C', 'M', 'X']; K = len(labels)\n",
    "    weight = torch.tensor([N / (K * counts.get(label)) for label in labels], dtype=torch.float32)\n",
    "    return weight\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"10-12\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 32\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = VGG()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    criterion_weight = _criterion_weight(train_csv)\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          criterion_weight = criterion_weight,\n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import Inception3\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "def _criterion_weight(csv):\n",
    "    \"\"\"计算损失函数权重\"\"\"\n",
    "    csv = pd.read_csv(csv); N = len(csv)\n",
    "    counts = csv['label'].value_counts().to_dict()\n",
    "    labels = ['NF', 'C', 'M', 'X']; K = len(labels)\n",
    "    weight = torch.tensor([N / (K * counts.get(label)) for label in labels], dtype=torch.float32)\n",
    "    return weight\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"10-12\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = Inception3()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    criterion_weight = _criterion_weight(train_csv)\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          criterion_weight = criterion_weight,\n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from Model import ResNet\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "def _criterion_weight(csv):\n",
    "    \"\"\"计算损失函数权重\"\"\"\n",
    "    csv = pd.read_csv(csv); N = len(csv)\n",
    "    counts = csv['label'].value_counts().to_dict()\n",
    "    labels = ['NF', 'C', 'M', 'X']; K = len(labels)\n",
    "    weight = torch.tensor([N / (K * counts.get(label)) for label in labels], dtype=torch.float32)\n",
    "    return weight\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"10-12\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "    \n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = ResNet()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    criterion_weight = _criterion_weight(train_csv)\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          criterion_weight = criterion_weight,\n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from Model import VisionTransformer\n",
    "from DataLoader import load_mag_data\n",
    "\n",
    "def _criterion_weight(csv):\n",
    "    \"\"\"计算损失函数权重\"\"\"\n",
    "    csv = pd.read_csv(csv); N = len(csv)\n",
    "    counts = csv['label'].value_counts().to_dict()\n",
    "    labels = ['NF', 'C', 'M', 'X']; K = len(labels)\n",
    "    weight = torch.tensor([N / (K * counts.get(label)) for label in labels], dtype=torch.float32)\n",
    "    return weight\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"===============================DATALOADER===============================\"\"\"\n",
    "    months = \"10-12\" # 交叉验证\n",
    "    train_csv = f\"/root/label/v0/{months}/train.csv\"\n",
    "    val_csv = f\"/root/label/v0/{months}/val.csv\"\n",
    "    test_csv = f\"/root/label/v0/{months}/test.csv\"\n",
    "   \n",
    "    root = \"/root/autodl-tmp/data/npz\"\n",
    "\n",
    "    trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize(size=(224,224), interpolation=InterpolationMode.BILINEAR)])\n",
    "    \n",
    "    batch_size = 96\n",
    "\n",
    "    # 训练集\n",
    "    train_iter = load_mag_data(csv=train_csv, root=root, transform=trans, \n",
    "                               batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "    \n",
    "    # 验证集\n",
    "    val_iter = load_mag_data(csv=val_csv, root=root, transform=trans, \n",
    "                             batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    # 测试集\n",
    "    test_iter = load_mag_data(csv=test_csv, root=root, transform=trans, \n",
    "                              batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    \"\"\"===============================MODEL===============================\"\"\"\n",
    "    model = VisionTransformer()\n",
    "    \n",
    "    \"\"\"===============================PARAMETER===============================\"\"\"\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.01\n",
    "    device = 'cuda'\n",
    "    saving_directory = os.path.join(\"/root/result/\", model._get_name())\n",
    "    os.makedirs(saving_directory, exist_ok=True)\n",
    "    lr_decay = True\n",
    "    lr_decay_step = 5\n",
    "    criterion_weight = _criterion_weight(train_csv)\n",
    "    test_index = pd.read_csv(test_csv)['date']\n",
    "    X_val_TSS_limit = 0.3\n",
    "\n",
    "    \"\"\"===============================TRAIN===============================\"\"\"\n",
    "    train(model = model,\n",
    "          train_iter = train_iter,\n",
    "          val_iter = val_iter,\n",
    "          test_iter = test_iter, \n",
    "          num_epochs = num_epochs,\n",
    "          lr = learning_rate,\n",
    "          weight_decay = weight_decay,\n",
    "          device = device,\n",
    "          saving_directory = saving_directory,\n",
    "          lr_decay = lr_decay,\n",
    "          lr_decay_step = lr_decay_step,  \n",
    "          criterion_weight = criterion_weight,\n",
    "          test_index = test_index,\n",
    "          X_val_TSS_limit = X_val_TSS_limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
